# -*- coding: utf-8 -*-
"""Copy of Student_mentalhealth_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eRayDZsqk7bU-eaLa_PLMeQApbMQepqP
"""

# STEP 1: Install Required Libraries
!pip install scikit-learn matplotlib seaborn pandas catboost xgboost lightgbm

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from google.colab import files

# High-Accuracy Models
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier

# STEP 2: Load Dataset
df = pd.read_csv("/students_mental_health_survey.csv")

# STEP 3: Categorize Mental Health Levels
def severity_from_score(score):
    if score == 0: return "Normal"
    elif score == 1: return "Mild"
    elif score == 2: return "Moderate"
    else: return "Severe"

categories = []
for i in range(len(df)):
    levels = [
        severity_from_score(df.loc[i, "Stress_Level"]),
        severity_from_score(df.loc[i, "Depression_Score"]),
        severity_from_score(df.loc[i, "Anxiety_Score"])
    ]
    severity_order = {"Normal": 0, "Mild": 1, "Moderate": 2, "Severe": 3}
    final_level = max(levels, key=lambda x: severity_order[x])
    categories.append(final_level)

df["Mental_Health_Status"] = categories

# STEP 4: Preprocessing
df.fillna(df.mode().iloc[0], inplace=True)

label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    if col != "Mental_Health_Status":
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

X = df.drop("Mental_Health_Status", axis=1)
y = df["Mental_Health_Status"]

target_le = LabelEncoder()
y_encoded = target_le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# STEP 5: High-Accuracy Models
models = {
    "CatBoost": CatBoostClassifier(verbose=0, random_state=42, depth=6, learning_rate=0.1, iterations=300),
    "XGBoost": XGBClassifier(eval_metric="mlogloss", random_state=42, n_estimators=300, max_depth=5,
                             learning_rate=0.1, subsample=0.9, colsample_bytree=0.9),
    "LightGBM": LGBMClassifier(random_state=42, n_estimators=300, num_leaves=31, learning_rate=0.1, subsample=0.9),
    "GradientBoosting": GradientBoostingClassifier(random_state=42, n_estimators=300, max_depth=5, learning_rate=0.1),
    "ExtraTrees": ExtraTreesClassifier(random_state=42, n_estimators=300, max_depth=None)
}

# STEP 6: Train + Evaluate
results = {}
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred) * 100
    results[name] = acc
    print(f"{name} Accuracy: {acc:.2f}%")
    print(classification_report(y_test, y_pred, target_names=target_le.classes_))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_le.classes_, yticklabels=target_le.classes_)
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

# STEP 7: Accuracy Comparison Chart
plt.figure(figsize=(10,6))
sns.barplot(x=list(results.keys()), y=list(results.values()), palette="Set2")
plt.ylabel("Accuracy (%)")
plt.ylim(95, 100)
plt.xticks(rotation=45)
plt.title("High-Accuracy Models (97-99%)")
plt.show()

# STEP 8: Save Predictions from Best Model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]

predictions = best_model.predict(X_test)
predicted_labels = target_le.inverse_transform(predictions)

# Save with features + true labels + predicted labels + correctness
df_test = pd.DataFrame(X_test, columns=X.columns)
df_test["True_Status"] = target_le.inverse_transform(y_test)
df_test["Predicted_Status"] = predicted_labels
df_test["Prediction_Correct"] = df_test["True_Status"] == df_test["Predicted_Status"]

# Add probability/confidence scores (if supported)
if hasattr(best_model, "predict_proba"):
    proba = best_model.predict_proba(X_test)
    proba_df = pd.DataFrame(proba, columns=[f"Prob_{cls}" for cls in target_le.classes_])
    df_test = pd.concat([df_test, proba_df], axis=1)

df_test.to_csv("mental_health_with_labels_and_predictions.csv", index=False)
print(f"\nBest model: {best_model_name} with {results[best_model_name]:.2f}% accuracy")
files.download("mental_health_with_labels_and_predictions.csv")

from google.colab import drive
drive.mount('/content/drive')